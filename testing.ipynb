{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"model/\")\n",
    "from diffusion import GaussianDiffusion, DiffusionImageAPI\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80x120]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"https://www.themoviedb.org/t/p/w1280/6oom5QYQ2yQTMJIbnvbkBL9cHo6.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "w, h = image.size\n",
    "image = image.resize((w // 16, h // 16))\n",
    "#image = image.resize((16, 16))\n",
    "w, h = image.size\n",
    "print(f\"[{w}x{h}]\")\n",
    "image\n",
    "image.save(\"./test.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = GaussianDiffusion(\n",
    "  model=None,\n",
    "  noise_steps=256,\n",
    "  beta_0=1e-4,\n",
    "  beta_T=0.02,\n",
    "  image_size=(w, h),\n",
    "  schedule=\"cosine\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "test = np.array(image)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "Shape of x: torch.Size([120, 80, 3])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32ms:\\Austin\\371Q\\movie-diffusion\\testing.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Austin/371Q/movie-diffusion/testing.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(\u001b[39mint\u001b[39m(timesteps[\u001b[39m0\u001b[39m])))\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Austin/371Q/movie-diffusion/testing.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#print(timesteps)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/s%3A/Austin/371Q/movie-diffusion/testing.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m images \u001b[39m=\u001b[39m imageAPI\u001b[39m.\u001b[39;49mget_noisy_images(image, time_steps\u001b[39m=\u001b[39;49mtimesteps)\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Austin/371Q/movie-diffusion/testing.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(images[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Austin/371Q/movie-diffusion/testing.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(images)):\n",
      "File \u001b[1;32ms:\\Austin\\371Q\\movie-diffusion\\model\\diffusion.py:169\u001b[0m, in \u001b[0;36mDiffusionImageAPI.get_noisy_images\u001b[1;34m(self, image, time_steps)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_noisy_images\u001b[39m(\u001b[39mself\u001b[39m, image, time_steps):\n\u001b[0;32m    164\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39m  image: the image to be processed PIL.Image\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m  time_steps: the number of time steps to apply noise (int)\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_noisy_image(image, \u001b[39mint\u001b[39m(t)) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m time_steps]\n",
      "File \u001b[1;32ms:\\Austin\\371Q\\movie-diffusion\\model\\diffusion.py:169\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_noisy_images\u001b[39m(\u001b[39mself\u001b[39m, image, time_steps):\n\u001b[0;32m    164\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39m  image: the image to be processed PIL.Image\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m  time_steps: the number of time steps to apply noise (int)\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_noisy_image(image, \u001b[39mint\u001b[39;49m(t)) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m time_steps]\n",
      "File \u001b[1;32ms:\\Austin\\371Q\\movie-diffusion\\model\\diffusion.py:155\u001b[0m, in \u001b[0;36mDiffusionImageAPI.get_noisy_image\u001b[1;34m(self, image, t)\u001b[0m\n\u001b[0;32m    153\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiffusion_model\u001b[39m.\u001b[39mnormalize_image(x)\n\u001b[0;32m    154\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(x))\n\u001b[1;32m--> 155\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiffusion_model\u001b[39m.\u001b[39;49mapply_noise(x, t)\n\u001b[0;32m    157\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiffusion_model\u001b[39m.\u001b[39mdenormalize_image(y)\n\u001b[0;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m Image\u001b[39m.\u001b[39mfromarray(y\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8))\n",
      "File \u001b[1;32ms:\\Austin\\371Q\\movie-diffusion\\model\\diffusion.py:82\u001b[0m, in \u001b[0;36mGaussianDiffusion.apply_noise\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(t) \u001b[39m==\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m     81\u001b[0m   t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([t])\n\u001b[1;32m---> 82\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mShape -> \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m-\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     83\u001b[0m sqrt_alpha_hat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(torch\u001b[39m.\u001b[39mtensor([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha_hat[t_] \u001b[39mfor\u001b[39;00m t_ \u001b[39min\u001b[39;00m t])\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice))\n\u001b[0;32m     84\u001b[0m sqrt_one_minus_alpha_hat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(torch\u001b[39m.\u001b[39mtensor([\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha_hat[t_] \u001b[39mfor\u001b[39;00m t_ \u001b[39min\u001b[39;00m t])\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shape' is not defined"
     ]
    }
   ],
   "source": [
    "imageAPI = DiffusionImageAPI(diffusion)\n",
    "timesteps = np.linspace(0, 255, 10).astype(int)\n",
    "print(type(int(timesteps[0])))\n",
    "#print(timesteps)\n",
    "\n",
    "images = imageAPI.get_noisy_images(image, time_steps=timesteps)\n",
    "print(images[0].shape)\n",
    "for i in range(len(images)):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  plt.imshow(images[i])\n",
    "  plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.Size([2, 1, 120, 80, 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([251])\n",
      "Value of t tensor([251])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32ms:\\Austin\\371Q\\movie-diffusion\\testing.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Austin/371Q/movie-diffusion/testing.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(t)\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Austin/371Q/movie-diffusion/testing.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m image \u001b[39m=\u001b[39m diffusion\u001b[39m.\u001b[39mapply_noise(image, t)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/s%3A/Austin/371Q/movie-diffusion/testing.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m imageAPI\u001b[39m.\u001b[39mtensor_to_image(diffusion\u001b[39m.\u001b[39mdenormalize_image(image\u001b[39m.\u001b[39;49msqueeze(\u001b[39m0\u001b[39m)))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'squeeze'"
     ]
    }
   ],
   "source": [
    "image = image_copy\n",
    "image = torch.from_numpy(np.array(image))\n",
    "image = diffusion.normalize_image(image)\n",
    "t = diffusion.sample_time_steps(1)\n",
    "print(t)\n",
    "image = diffusion.apply_noise(image, t)\n",
    "imageAPI.tensor_to_image(diffusion.denormalize_image(image.squeeze(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie-diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
